# Example vLLM server configuration
# Copy this file and customize as needed

model: Qwen/Qwen3-30B-A3B-Instruct-2507
host: 0.0.0.0
port: 8000
max_model_len: 262144
gpu_memory_utilization: 0.9
tensor_parallel_size: 1
trust_remote_code: false
