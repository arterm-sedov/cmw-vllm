# vLLM Server Configuration
VLLM_MODEL=Qwen/Qwen3-30B-A3B-Instruct-2507
VLLM_PORT=8000
VLLM_HOST=0.0.0.0
VLLM_MAX_MODEL_LEN=262144
VLLM_GPU_MEMORY_UTILIZATION=0.9
VLLM_TENSOR_PARALLEL_SIZE=1

# Model Download Configuration
MODEL_DOWNLOAD_DIR=
HF_CACHE_DIR=

# Logging
LOG_LEVEL=INFO
